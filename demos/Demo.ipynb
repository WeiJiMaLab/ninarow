{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your other imports here ...\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO: replace with your path/to/ninarow\n",
    "ninarowdir = os.path.dirname(os.getcwd())\n",
    "modelfitdir = ninarowdir + \"/model_fitting/\"\n",
    "# os.listdir(modelfitdir)\n",
    "\n",
    "# sets the import path to the model-fitting directory\n",
    "sys.path.insert(0, modelfitdir)\n",
    "from parsers import *\n",
    "# from new_fit import *\n",
    "from utils import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "# WARNING: %load_ext autoreload and %autoreload 2 may interfere with \n",
    "# the Multi-threading processes!\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building output directory at ../data/out\n",
      "Detected splits in this directory. Loading splits ...\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data\"\n",
    "output_path = \"../data/out\"\n",
    "n_splits = 5\n",
    "fold_number = 1\n",
    "threads = 1\n",
    "random_sample = False\n",
    "verbose = True\n",
    "\n",
    "print(f\"Building output directory at {output_path}\")\n",
    "os.makedirs(output_path, exist_ok = True)\n",
    "\n",
    "# first, we have to check to see if all the splits are there ...\n",
    "assert np.all([f\"{i + 1}.csv\" in os.listdir(data_path) for i in range(n_splits)])\n",
    "print(\"Detected splits in this directory. Loading splits ...\")\n",
    "\n",
    "# then we read them in\n",
    "splits = [pd.read_csv(f\"{data_path}/{i + 1}.csv\") for i in range(n_splits)]\n",
    "\n",
    "# we convert every row of our CSV to a \"CSVMove object\" using df_to_CSVMove - we do so for all the splits\n",
    "# CSVMove is a class that is defined in the parsers.py file \n",
    "fold_data = [[csvmove for csvmove in df_to_CSVMove(split, warn = False)] for split in splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'newfit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnewfit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m time\n\u001b[1;32m      3\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'newfit'"
     ]
    }
   ],
   "source": [
    "from newfit import *\n",
    "from time import time\n",
    "random.seed(10)\n",
    "initialize_thread_pool(1, manual_seed = 10)\n",
    "model_fitter =  ModelFitter(DefaultModel(), \n",
    "                           random_sample = random_sample, \n",
    "                           verbose = verbose, \n",
    "                           threads = threads)\n",
    "\n",
    "tick = time()\n",
    "q = model_fitter.estimate_l_values(fold_data[2], model_fitter.model.initial_params, 10)\n",
    "print(time() - tick)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting manual seed 10 for single-thread\n",
      "Thread 0: Base Seed 10, Seed: 10, Random Number: 601088376405717203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.61it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 15298.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.212856292724609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.492891879325427,\n",
       " 1.1400000000000001,\n",
       " 0.3,\n",
       " 1.2452056277056276,\n",
       " 1.6852489177489176,\n",
       " 4.38893269052609]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from new_fit import *\n",
    "from time import time\n",
    "random.seed(10)\n",
    "initialize_thread_pool(1, manual_seed = 10)\n",
    "model_fitter =  ModelFitter2(DefaultModel(), \n",
    "                           random_sample = random_sample, \n",
    "                           verbose = verbose, \n",
    "                           threads = threads)\n",
    "\n",
    "tick = time()\n",
    "q = model_fitter.estimate_l_values(fold_data[2], model_fitter.model.initial_params, 10)\n",
    "print(time() - tick)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_log_likelihood(dataloader, params, n_samples): \n",
    "    trackers = {x: {\"move\": y, \n",
    "                \"tracker\": \n",
    "                    {\"attempt_count\": 0, \n",
    "                     \"success_count\": 0, \n",
    "                     \"log_likelihood\": 0\n",
    "                     }\n",
    "                } \n",
    "            for (x, y) in dataloader()}\n",
    "    \n",
    "    log_likelihoods = []\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_fit import *\n",
    "random.seed(10)\n",
    "initialize_thread_pool(1, manual_seed = 10)\n",
    "model_fitter.fit_model(fold_data[fold_number - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "fold_dataloader = DataLoader(splits[fold_number - 1])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Board(black = 17179873280, white = 4194304): {'move': 21,\n",
       "  'tracker': {'attempt_count': 0, 'success_count': 0, 'log_likelihood': 0}},\n",
       " Board(black = 17180921856, white = 6291456): {'move': 23,\n",
       "  'tracker': {'attempt_count': 0, 'success_count': 0, 'log_likelihood': 0}},\n",
       " Board(black = 4096, white = 0): {'move': 22,\n",
       "  'tracker': {'attempt_count': 0, 'success_count': 0, 'log_likelihood': 0}},\n",
       " Board(black = 17197699080, white = 14688256): {'move': 4,\n",
       "  'tracker': {'attempt_count': 0, 'success_count': 0, 'log_likelihood': 0}},\n",
       " Board(black = 4294967296, white = 0): {'move': 22,\n",
       "  'tracker': {'attempt_count': 0, 'success_count': 0, 'log_likelihood': 0}},\n",
       " Board(black = 2101250, white = 24): {'move': 5,\n",
       "  'tracker': {'attempt_count': 0, 'success_count': 0, 'log_likelihood': 0}}}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trackers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(17179873280\t4194304\tWhite\t2097152\t1.0\t1\t1, 1 0 1), (17180921856\t6291456\tWhite\t8388608\t1.0\t1\t1, 1 0 1), (4096\t0\tWhite\t4194304\t1.0\t1\t1, 1 0 1), (17197699080\t14688256\tWhite\t16\t1.0\t1\t1, 1 0 1), (4294967296\t0\tWhite\t4194304\t1.0\t1\t1, 1 0 1), (2101250\t24\tWhite\t32\t1.0\t1\t1, 1 0 1)])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move_tasks.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(17179873280\t4194304\tWhite\t2097152\t1.0\t1\t1, 1 0 1),\n",
       " (17180921856\t6291456\tWhite\t8388608\t1.0\t1\t1, 1 0 1),\n",
       " (4096\t0\tWhite\t4194304\t1.0\t1\t1, 1 0 1),\n",
       " (17197699080\t14688256\tWhite\t16\t1.0\t1\t1, 1 0 1),\n",
       " (4294967296\t0\tWhite\t4194304\t1.0\t1\t1, 1 0 1),\n",
       " (2101250\t24\tWhite\t32\t1.0\t1\t1, 1 0 1)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: not x[1].is_done(), move_tasks.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "\n",
    "cutoff = 3.5\n",
    "trials = fold_data[fold_number - 1]\n",
    "expt_factor = 1.0\n",
    "\n",
    "success_threshold = 1 # when \"success_count\" reaches this value, the tracker is considered done\n",
    "\n",
    "\n",
    "n_trials = len(trials)\n",
    "cumulative_cutoff = n_trials * cutoff\n",
    "\n",
    "# trackers keeps track of the attempts and successes for IBS\n",
    "data = dict(zip(trials, [{\"attempt_count\": 0, \"success_count\": 0, \"log_likelihood\": 0}] * n_trials))\n",
    "dataloader = UltraDict(data, full_dump_size=n_trials*1024*1024, shared_lock = True) # buffer size is set to n_trials megabytes\n",
    "\n",
    "global Lexpt\n",
    "Lexpt.value =  n_trials * expt_factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2690890031.py, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[45], line 33\u001b[0;36m\u001b[0m\n\u001b[0;31m    delta_expected_log_likelihood = -scaling_factor * 1/tracker[]\u001b[0m\n\u001b[0m                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "scaling_factor = expt_factor / success_threshold\n",
    "\n",
    "for _ in range(1):\n",
    "\n",
    "    # incomplete_trials keeps track of all the trials that haven't yet reached the threshold to be considered \"done\"\n",
    "    incomplete_trials = list(filter(lambda x: x[1][\"success_count\"] < success_threshold, trackers.items()))\n",
    "\n",
    "    # if there are no more incomplete trials or if the Lexpt value is greater than the cutoff, we're done\n",
    "    if not incomplete_trials or Lexpt.value > cutoff: \n",
    "        break\n",
    "\n",
    "    # choose a trial at random, and get its tracker\n",
    "    data, tracker = copy.deepcopy(random.choice(incomplete_trials))\n",
    "\n",
    "    # accumulates all the changes we need to make to the expected log likelihood\n",
    "    batch_delta_expected_log_likelihood = 0\n",
    "\n",
    "    while tracker[\"success_count\"] < success_threshold: \n",
    "        predicted_move = model.predict(data.board)\n",
    "        actual_move = data.move.board_position\n",
    "\n",
    "        # increment the attempt count\n",
    "        tracker[\"attempt_count\"] += 1\n",
    "\n",
    "        # calculate the change in expected log likelihood\n",
    "        # according to IBS, L = sum_k 1/k\n",
    "        # where k here is the attempt count\n",
    "        delta_expected_log_likelihood = -scaling_factor * 1/tracker[\"attempt_count\"]\n",
    "\n",
    "        # accumulate this change to the batch\n",
    "        batch_delta_expected_log_likelihood += delta_expected_log_likelihood\n",
    "\n",
    "        # update the log likelihood for this trial\n",
    "        tracker[\"log_likelihood\"] += delta_expected_log_likelihood\n",
    "\n",
    "        # register a hit! and we're done with this trial\n",
    "        if predicted_move == actual_move:\n",
    "            # increment the success count and reset the attempts to 0\n",
    "            tracker[\"success_count\"] += 1\n",
    "            tracker[\"attempt_count\"] = 0\n",
    "            with trackers.lock: \n",
    "                if tracker[\"success_count\"] == trackers[data][\"success_count\"]:\n",
    "                    trackers[data] = tracker\n",
    "                    Lexpt.value += batch_delta_expected_log_likelihood\n",
    "            break\n",
    "        \n",
    "        # if the expected log likelihood is greater than the cutoff, we're done\n",
    "        if Lexpt.value + batch_delta_expected_log_likelihood > cutoff: \n",
    "            with trackers.lock: \n",
    "                Lexpt.value += batch_delta_expected_log_likelihood\n",
    "            break\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        delta_expected_log_likelihood = -scaling_factor * 1/tracker[\"attempt_count\"]\n",
    "        tracker[\"log_likelihood\"] += delta_expected_log_likelihood\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        # delta_expected_log_likelihood\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
