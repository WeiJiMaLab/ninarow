{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe18e5e4-1afd-4949-b2d1-850f76d205e5",
   "metadata": {},
   "source": [
    "# Tree Search Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eafb54-e8c9-4245-a780-7e5a2d76df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your other imports here ...\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO: replace with your path/to/ninarow\n",
    "ninarowdir = os.path.dirname(os.getcwd())\n",
    "modelfitdir = ninarowdir + \"/model_fitting/\"\n",
    "# os.listdir(modelfitdir)\n",
    "\n",
    "# sets the import path to the model-fitting directory\n",
    "sys.path.insert(0, modelfitdir)\n",
    "from parsers import *\n",
    "from model_fit import *\n",
    "from utils import *\n",
    "import model_fit\n",
    "from tqdm import tqdm\n",
    "\n",
    "# WARNING: %load_ext autoreload and %autoreload 2 may interfere with \n",
    "# the Multi-threading processes!\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6157b8-7034-436d-b9bd-955041d96492",
   "metadata": {},
   "source": [
    "# Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341377a9-51b4-44a6-b96d-918d52120dcb",
   "metadata": {},
   "source": [
    "### File Formatting\n",
    "The data columns should be ordered: \n",
    "\n",
    "    - black_pieces (binary), \n",
    "    - white_pieces (binary), \n",
    "    - player_color (Black/White), \n",
    "    - move (binary), \n",
    "    - response time (not used in fitting), \n",
    "    - [group_id] (optional), \n",
    "    - participant_id\n",
    "\n",
    "for more info, see `parsers.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba4e82b-27fe-4e19-be47-16477aacefbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make a folder (here I've called it \"data/\")\n",
    "# which holds your data in a csv called data.csv and put its directory here ...\n",
    "data_path = \"../data\"\n",
    "data_csv = f\"{data_path}/data.csv\"\n",
    "df = pd.read_csv(data_csv)[:30]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea38fe5-753a-461b-8465-34e441081345",
   "metadata": {},
   "source": [
    "We can show the boards using the `show` function from `utils`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4952f00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import show\n",
    "\n",
    "fig = plt.figure(figsize = (16, 12))\n",
    "for i, row in enumerate(df.head(9).itertuples()): \n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    show(row.black, row.white, existing_fig=(fig, ax))\n",
    "    ax.set_title(f\"Row {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75098c5f-da02-4539-a9f4-e179edac810d",
   "metadata": {},
   "source": [
    "## Creating Cross Validation Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c4d75a",
   "metadata": {},
   "source": [
    "We can easily create cross validation splits by using `utils.make_splits`, which takes in a dataframe\n",
    "and outputs into a specified `data_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af98f8e-2525-4405-8bc5-c180356314a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import make_splits\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(10)\n",
    "np.random.seed(10)\n",
    "\n",
    "splits = make_splits(df, output_dir = data_path)\n",
    "# view the first few lines of the first split\n",
    "splits[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b120b-c352-420a-81d1-214948793957",
   "metadata": {},
   "source": [
    "The parser takes in a CSV filename and turns it into a list of \n",
    "objects of type CSVMove ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd44263-aa78-4d10-bd90-c418a692eb05",
   "metadata": {},
   "source": [
    "# Fitting the Model to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec60ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data\"\n",
    "output_path = \"../data/out\"\n",
    "n_splits = 5\n",
    "fold_number = 1\n",
    "threads = 1\n",
    "random_sample = False\n",
    "verbose = True\n",
    "\n",
    "print(f\"Building output directory at {output_path}\")\n",
    "os.makedirs(output_path, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16ea3ac-c9f7-4643-b3e2-8d5677b40b99",
   "metadata": {},
   "source": [
    "## Part 1: Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f73bed-2f4f-434b-bbaa-58d756a9ad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we have to check to see if all the splits are there ...\n",
    "assert np.all([f\"{i + 1}.csv\" in os.listdir(data_path) for i in range(n_splits)])\n",
    "print(\"Detected splits in this directory. Loading splits ...\")\n",
    "\n",
    "# then we read them in\n",
    "splits = [pd.read_csv(f\"{data_path}/{i + 1}.csv\") for i in range(n_splits)]\n",
    "\n",
    "# we convert every row of our CSV to a \"CSVMove object\" using df_to_CSVMove - we do so for all the splits\n",
    "# CSVMove is a class that is defined in the parsers.py file \n",
    "fold_data = [[csvmove for csvmove in df_to_CSVMove(split, warn = False)] for split in splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39935041",
   "metadata": {},
   "source": [
    "## Part 2: Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477a57ef",
   "metadata": {},
   "source": [
    "To ensure that the code is perfectly reproducible, we use a **single thread** and we set the manual seed to a number of our choosing. If we use multiple threads, the code will still work but the operating system may choose the order of the threads arbitrarily, leading to variation in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16a2d5d",
   "metadata": {},
   "source": [
    "You should see an output that looks something like: \n",
    "\n",
    "    Setting manual seed 10 for single-thread\n",
    "    Thread 0: Base Seed 10, Seed: 10, Random Number: 601088376405717203\n",
    "\n",
    "Note that if you run this code multiple times, the Random Number should be the same. This means our thread will be initialized with a particular random seed - as it runs, it will not be reinitialized, so the randomness will still proceed, but in a predictable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b8cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, Value, set_start_method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df73ec0",
   "metadata": {},
   "source": [
    "We are now ready to begin running our model. We will begin with the default model and then feed it to our  `ModelFitter` class. Note that this code may take a very long time to run (a couple hours)...\n",
    "\n",
    "If you are using multiple threads and seeing a thread-related error, please make sure to turn OFF `%load_ext autoreload` and `%autoreload 2` from the import statements above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ea19a9-5155-4b01-b72d-3923b413d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "initialize_global_threads(1, manual_seed = 10)\n",
    "\n",
    "model_fitter = ModelFitter(DefaultModel(), \n",
    "                           random_sample = random_sample, \n",
    "                           verbose = verbose, \n",
    "                           threads = threads)\n",
    "\n",
    "params, loglik_train, loglik_test = model_fitter.cross_validate(fold_data, fold_number - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a6f368",
   "metadata": {},
   "source": [
    "We can examine the fitted model parameters below ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75555658",
   "metadata": {},
   "outputs": [],
   "source": [
    "loglik_train_df = pd.DataFrame(loglik_train, columns = [\"loglik_train\"])\n",
    "loglik_test_df = pd.DataFrame(loglik_test, columns = [\"loglik_test\"])\n",
    "\n",
    "print(\"Fitted Model Parameters\")\n",
    "param_df = pd.DataFrame(dict(zip(model_fitter.model.param_names, params), index = [0])).drop(\"index\", axis = 1)\n",
    "param_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c963c43",
   "metadata": {},
   "source": [
    "## Part 3: Saving Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae9488",
   "metadata": {},
   "source": [
    "We will save the log likelihood for the train and test folds, as well as the parameters, as `{fold_number}_lltrain.csv`, `{fold_number}_lltest.csv`, and `{fold_number}_params.csv` in the directory specified by `{output_path}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "cbac9d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loglik_train_df.to_csv(f\"{output_path}/{fold_number}_lltrain.csv\", index = False)\n",
    "loglik_test_df.to_csv(f\"{output_path}/{fold_number}_lltest.csv\", index = False)\n",
    "param_df.to_csv(f\"{output_path}/{fold_number}_params.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d58722",
   "metadata": {},
   "source": [
    "# Running an Existing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8add4056",
   "metadata": {},
   "source": [
    "## Loading the Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1414ce28",
   "metadata": {},
   "source": [
    "First, let's load our model parameters in from a csv file ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8492f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_path = f\"{output_path}/{fold_number}_params.csv\"\n",
    "param_df = pd.read_csv(param_path)\n",
    "params = param_df.iloc[0].values\n",
    "\n",
    "# set the parameters of the model that will be used in the tree search\n",
    "model = DefaultModel()\n",
    "heuristic = model.create_heuristic(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b54e53",
   "metadata": {},
   "source": [
    "## Predicting moves on an example board"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a5a63",
   "metadata": {},
   "source": [
    "Let's start by taking an arbitrary board state and run our model prediction on it ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b74e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "black = 16793616\t\n",
    "white = 12582912\n",
    "show(black, white)\n",
    "\n",
    "# create a fourbynineboard object out of our patterns ...\n",
    "board = fourbynine_board(fourbynine_pattern(black), fourbynine_pattern(white))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "dc6c93a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = model.create_search(params, heuristic, board)\n",
    "search.complete_search()\n",
    "best_move_index = heuristic.get_best_move(search.get_tree()).board_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a76abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (4, 3))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "show(black, white, existing_fig=(fig, ax))\n",
    "add_circle(best_move_index, existing_fig=(fig, ax), color = \"blue\")\n",
    "print(\"Predicted Move shown in BLUE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2e9771",
   "metadata": {},
   "source": [
    "## Make a Heatmap of Predictions from Multiple Searches\n",
    "You might notice that there is noisiness in the behavior of the model. To show how the model behaves over several runs, we'll want to show a heatmap of the different predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ecfa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "counts = np.zeros(36)\n",
    "for _ in tqdm(range(n_samples), leave=True): \n",
    "    search = model.create_search(params, heuristic, board)\n",
    "    search.complete_search()\n",
    "    best_move_index = heuristic.get_best_move(search.get_tree()).board_position\n",
    "    counts[best_move_index] += 1\n",
    "\n",
    "fig = plt.figure(figsize = (4, 3))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "show(black, white, existing_fig=(fig, ax))\n",
    "\n",
    "# the [::-1] is to flip the board because of a quirk in the way the board is plotted\n",
    "# you basically have to mirror it over the y-axis (see \"extent\" below)\n",
    "ax.imshow(counts.reshape(4, 9)[::-1], cmap = \"Blues\", extent=[85, 715, -160, -440], alpha = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
