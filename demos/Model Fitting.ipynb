{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe18e5e4-1afd-4949-b2d1-850f76d205e5",
   "metadata": {},
   "source": [
    "# Demo Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86eafb54-e8c9-4245-a780-7e5a2d76df6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your other imports here ...\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: replace with your path/to/ninarow\n",
    "ninarowdir = os.path.dirname(os.getcwd())\n",
    "modelfitdir = ninarowdir + \"/model_fitting/\"\n",
    "# os.listdir(modelfitdir)\n",
    "\n",
    "# sets the import path to the model-fitting directory\n",
    "sys.path.insert(0, modelfitdir)\n",
    "from parsers import *\n",
    "from model_fit import *\n",
    "import model_fit\n",
    "\n",
    "# WARNING: DO NOT USE %load_ext autoreload and %autoreload 2 as it interferes with \n",
    "# the Multi-threading processes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6157b8-7034-436d-b9bd-955041d96492",
   "metadata": {},
   "source": [
    "## Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341377a9-51b4-44a6-b96d-918d52120dcb",
   "metadata": {},
   "source": [
    "### File Formatting\n",
    "The data columns should be ordered: \n",
    "\n",
    "    - black_pieces (binary), \n",
    "    - white_pieces (binary), \n",
    "    - player_color (Black/White), \n",
    "    - move (binary), \n",
    "    - response time (not used in fitting), \n",
    "    - [group_id] (optional), \n",
    "    - participant_id\n",
    "\n",
    "for more info, see `parsers.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a6bf99e-4718-4d74-a625-1ab5746c4c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data\"\n",
    "df = pd.read_pickle(f\"{data_path}/data.pkl\")\n",
    "df[\"response_time\"] = 1\n",
    "df[\"participant_id\"] = 1 # in the demo, there is only one participant, but if you have multiple, you may want to change this\n",
    "df[\"black\"] = df[\"bp\"]\n",
    "df[\"white\"] = df[\"wp\"]\n",
    "df = df[:10][[\"black\", \"white\", \"color\", \"move\", \"response_time\", \"participant_id\"]]\n",
    "df.to_csv(f\"{data_path}/data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eba4e82b-27fe-4e19-be47-16477aacefbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make a folder (here I've called it \"data/\")\n",
    "# which holds your data in a csv called data.csv and put its directory here ...\n",
    "data_dir = \"../data\"\n",
    "data_csv = f\"{data_dir}/data.csv\"\n",
    "df = pd.read_csv(data_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea38fe5-753a-461b-8465-34e441081345",
   "metadata": {},
   "source": [
    "This is what our data looks like in our CSV ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75098c5f-da02-4539-a9f4-e179edac810d",
   "metadata": {},
   "source": [
    "## Cross Validation Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5457552-096d-43f3-92c0-6b3efcb66782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import make_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4af98f8e-2525-4405-8bc5-c180356314a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving split1 to ../data/1.csv\n",
      "Saving split2 to ../data/2.csv\n",
      "Saving split3 to ../data/3.csv\n",
      "Saving split4 to ../data/4.csv\n",
      "Saving split5 to ../data/5.csv\n"
     ]
    }
   ],
   "source": [
    "splits = make_splits(df, output_dir = data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "563a98d9-51b1-47c5-969b-ad79b2a2c8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>color</th>\n",
       "      <th>move</th>\n",
       "      <th>response_time</th>\n",
       "      <th>participant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>4194304</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2684354560</td>\n",
       "      <td>4194304</td>\n",
       "      <td>White</td>\n",
       "      <td>2097152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        black    white  color     move  response_time  participant_id\n",
       "0        8192        0  White  4194304              1               1\n",
       "1  2684354560  4194304  White  2097152              1               1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16ea3ac-c9f7-4643-b3e2-8d5677b40b99",
   "metadata": {},
   "source": [
    "## Load Data into Model Fitting Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c47e85d1-7f53-481f-8a17-38f5860d685a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Column 'reaction_time' not found in DataFrame. Defaulting to 1.0 for all moves.\n",
      "Warning: Column 'group_id' not found in DataFrame. Defaulting to 1 for all moves.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8192\t0\tWhite\t4194304\t1.0\t1\t1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import *\n",
    "[csvmove for csvmove in df_to_CSVMove(splits[0])][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b120b-c352-420a-81d1-214948793957",
   "metadata": {},
   "source": [
    "The parser takes in a CSV filename and turns it into a list of \n",
    "objects of type CSVMove ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "325a7229-8994-4231-ad52-28b9f9243a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is either not a JSON file, or is malformed. Attempting to parse as a CSV...\n",
      "the rows are type <class 'parsers.CSVMove'>\n",
      "and they look like\n",
      "[8192\t0\tWhite\t4194304\t1.0\t1\t1, 2684354560\t4194304\tWhite\t2097152\t1.0\t1\t1]\n"
     ]
    }
   ],
   "source": [
    "data = parse_participant_file(f\"{data_path}/1.csv\", ignore_csv_header = True)\n",
    "print(f\"the rows are type {type(data[0])}\")\n",
    "print(\"and they look like\")\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd44263-aa78-4d10-bd90-c418a692eb05",
   "metadata": {},
   "source": [
    "### Making Cross Validation Splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4f73bed-2f4f-434b-bbaa-58d756a9ad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected splits in this directory. Loading splits ...\n",
      "Building output directory at ../data/out\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data\"\n",
    "output_path = \"../data/out\"\n",
    "n_splits = 5\n",
    "fold_number = 1\n",
    "threads = 1\n",
    "random_sample = False\n",
    "verbose = True\n",
    "\n",
    "\n",
    "assert np.all([f\"{i + 1}.csv\" in os.listdir(data_path) for i in range(n_splits)])\n",
    "\n",
    "print(\"Detected splits in this directory. Loading splits ...\")\n",
    "splits = [pd.read_csv(f\"{data_dir}/{i + 1}.csv\") for i in range(n_splits)]\n",
    "fold_data = [[csvmove for csvmove in df_to_CSVMove(split, warn = False)] for split in splits]\n",
    "\n",
    "print(f\"Building output directory at {output_path}\")\n",
    "os.makedirs(output_path, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9ea19a9-5155-4b01-b72d-3923b413d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, Value, set_start_method\n",
    "\n",
    "random.seed(10)\n",
    "initialize_global_threads(1)\n",
    "model_fitter = ModelFitter(DefaultModel(), \n",
    "                           random_sample = random_sample, \n",
    "                           verbose = verbose, \n",
    "                           threads = threads)\n",
    "\n",
    "params, loglik_train, loglik_test = model_fitter.cross_validate(fold_data, fold_number - 1)\n",
    "# with (output_path / (\"params\" + str(i + 1) + \".csv\")).open('w') as f:\n",
    "#     f.write(','.join(str(x) for x in params))\n",
    "# with (output_path / (\"lltrain\" + str(i + 1) + \".csv\")).open('w') as f:\n",
    "#     f.write(','.join(str(x) for x in loglik_train))\n",
    "# with (output_path / (\"lltest\" + str(i + 1) + \".csv\")).open('w') as f:\n",
    "#     f.write(' '.join(str(x) for x in loglik_test) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efdba8c-a909-47d5-a96f-837a23e688fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "initialize_thread_pool(Value('d', 0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef00352-849c-428b-9424-e4c8bf3b7526",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "random.randint(0, 2**64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a553b054-0c47-4977-bb63-e634c39f2ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.randint(0, 2**64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cbc3e5-2e63-4a60-9359-d9f07cd6f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)\n",
    "\n",
    "initialize_pool(Value('d', 0), 1)\n",
    "model_fitter = ModelFitter(DefaultModel(), \n",
    "                           random_sample = random_sample, \n",
    "                           verbose = verbose, \n",
    "                           threads = threads)\n",
    "\n",
    "params, loglik_train, loglik_test = model_fitter.cross_validate(fold_data, fold_number - 1)\n",
    "with (output_path / (\"params\" + str(i + 1) + \".csv\")).open('w') as f:\n",
    "    f.write(','.join(str(x) for x in params))\n",
    "with (output_path / (\"lltrain\" + str(i + 1) + \".csv\")).open('w') as f:\n",
    "    f.write(','.join(str(x) for x in loglik_train))\n",
    "with (output_path / (\"lltest\" + str(i + 1) + \".csv\")).open('w') as f:\n",
    "    f.write(' '.join(str(x) for x in loglik_test) + '\\n')\n",
    "\n",
    "# [1] NLL: 25.4614 Params: [1.053, 0.68, 0.147, 0.292, 0.539, 0.952, -1.899, -1.372, -4.072, -3.799]\n",
    "# [2] NLL: 21.8845 Params: [1.334, 0.294, 0.414, 0.005, 1.939, -4.663, -4.106, 4.424, -3.281, 2.393]\n",
    "# [3] NLL: 24.2337 Params: [1.632, 0.782, 0.037, 0.156, 1.082, -3.052, 3.237, 1.782, -0.542, -3.545]\n",
    "# [4] NLL: 24.5092 Params: [1.913, 0.396, 0.272, 0.423, 1.346, 1.294, 0.444, -4.99, -2.114, 0.264]\n",
    "# [5] NLL: 24.6297 Params: [2.396, 0.624, 0.304, 0.122, 1.769, -2.373, 1.753, -1.235, 2.314, -0.088]\n",
    "# [6] NLL: 23.613 Params: [2.677, 0.127, 0.006, 0.331, 0.755, 3.271, 4.585, 3.037, 0.02, 3.682]\n",
    "# [7] NLL: 17.8836 Params: [2.958, 0.95, 0.381, 0.446, 1.61, 4.17, -3.071, 0.669, 3.696, -2.256]\n",
    "# [8] NLL: 26.7262 Params: [3.239, 0.452, 0.176, 0.225, 0.96, -0.225, -0.903, -2.627, 3.96, 3.975]\n",
    "# [9] NLL: 26.1641 Params: [3.375, 0.326, 0.09, 0.276, 1.549, -3.745, -0.22, -3.428, 4.937, -2.988]\n",
    "# [10] NLL: 21.9883 Params: [3.656, 0.824, 0.354, 0.055, 0.887, 1.909, -3.599, 0.22, 2.72, 0.645]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "singularity",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
