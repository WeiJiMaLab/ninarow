{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe18e5e4-1afd-4949-b2d1-850f76d205e5",
   "metadata": {},
   "source": [
    "# Demo Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86eafb54-e8c9-4245-a780-7e5a2d76df6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# your other imports here ...\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "\n",
    "# TODO: replace with your path/to/ninarow\n",
    "ninarowdir = os.path.dirname(os.getcwd())\n",
    "modelfitdir = ninarowdir + \"/model_fitting/\"\n",
    "# os.listdir(modelfitdir)\n",
    "\n",
    "# sets the import path to the model-fitting directory\n",
    "sys.path.insert(0, modelfitdir)\n",
    "from parsers import *\n",
    "from model_fit import *\n",
    "import model_fit\n",
    "\n",
    "# WARNING: DO NOT USE %load_ext autoreload and %autoreload 2 may interfere with \n",
    "# the Multi-threading processes!\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6157b8-7034-436d-b9bd-955041d96492",
   "metadata": {},
   "source": [
    "## Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341377a9-51b4-44a6-b96d-918d52120dcb",
   "metadata": {},
   "source": [
    "### File Formatting\n",
    "The data columns should be ordered: \n",
    "\n",
    "    - black_pieces (binary), \n",
    "    - white_pieces (binary), \n",
    "    - player_color (Black/White), \n",
    "    - move (binary), \n",
    "    - response time (not used in fitting), \n",
    "    - [group_id] (optional), \n",
    "    - participant_id\n",
    "\n",
    "for more info, see `parsers.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a6bf99e-4718-4d74-a625-1ab5746c4c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"../data\"\n",
    "# df = pd.read_pickle(f\"{data_path}/data.pkl\")\n",
    "# df[\"response_time\"] = 1\n",
    "# df[\"participant_id\"] = 1 # in the demo, there is only one participant, but if you have multiple, you may want to change this\n",
    "# df[\"black\"] = df[\"bp\"]\n",
    "# df[\"white\"] = df[\"wp\"]\n",
    "# df = df[:10][[\"black\", \"white\", \"color\", \"move\", \"response_time\", \"participant_id\"]]\n",
    "# df.to_csv(f\"{data_path}/data.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eba4e82b-27fe-4e19-be47-16477aacefbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>color</th>\n",
       "      <th>move</th>\n",
       "      <th>response_time</th>\n",
       "      <th>participant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>4194304</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16400</td>\n",
       "      <td>4194304</td>\n",
       "      <td>White</td>\n",
       "      <td>8388608</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16793616</td>\n",
       "      <td>12582912</td>\n",
       "      <td>White</td>\n",
       "      <td>2097152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>4194304</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2105344</td>\n",
       "      <td>4194304</td>\n",
       "      <td>White</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      black     white  color     move  response_time  participant_id\n",
       "0        16         0  White  4194304              1               1\n",
       "1     16400   4194304  White  8388608              1               1\n",
       "2  16793616  12582912  White  2097152              1               1\n",
       "3      8192         0  White  4194304              1               1\n",
       "4   2105344   4194304  White       16              1               1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: make a folder (here I've called it \"data/\")\n",
    "# which holds your data in a csv called data.csv and put its directory here ...\n",
    "data_path = \"../data\"\n",
    "data_csv = f\"{data_path}/data.csv\"\n",
    "df = pd.read_csv(data_csv)[:10]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea38fe5-753a-461b-8465-34e441081345",
   "metadata": {},
   "source": [
    "This is what our data looks like in our CSV ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75098c5f-da02-4539-a9f4-e179edac810d",
   "metadata": {},
   "source": [
    "## Creating Cross Validation Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c4d75a",
   "metadata": {},
   "source": [
    "We can easily create cross validation splits by using `utils.make_splits`, which takes in a dataframe\n",
    "and outputs into a specified `data_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af98f8e-2525-4405-8bc5-c180356314a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving split1 to ../data/1.csv\n",
      "Saving split2 to ../data/2.csv\n",
      "Saving split3 to ../data/3.csv\n",
      "Saving split4 to ../data/4.csv\n",
      "Saving split5 to ../data/5.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>color</th>\n",
       "      <th>move</th>\n",
       "      <th>response_time</th>\n",
       "      <th>participant_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16400</td>\n",
       "      <td>4194304</td>\n",
       "      <td>White</td>\n",
       "      <td>8388608</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2684354560</td>\n",
       "      <td>4194304</td>\n",
       "      <td>White</td>\n",
       "      <td>2097152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        black    white  color     move  response_time  participant_id\n",
       "0       16400  4194304  White  8388608              1               1\n",
       "1  2684354560  4194304  White  2097152              1               1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import make_splits\n",
    "splits = make_splits(df, output_dir = data_path)\n",
    "\n",
    "# view the first few lines of the first split\n",
    "splits[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b120b-c352-420a-81d1-214948793957",
   "metadata": {},
   "source": [
    "The parser takes in a CSV filename and turns it into a list of \n",
    "objects of type CSVMove ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd44263-aa78-4d10-bd90-c418a692eb05",
   "metadata": {},
   "source": [
    "# Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec60ffb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building output directory at ../data/out\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data\"\n",
    "output_path = \"../data/out\"\n",
    "n_splits = 5\n",
    "fold_number = 1\n",
    "threads = 1\n",
    "random_sample = False\n",
    "verbose = True\n",
    "\n",
    "print(f\"Building output directory at {output_path}\")\n",
    "os.makedirs(output_path, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16ea3ac-c9f7-4643-b3e2-8d5677b40b99",
   "metadata": {},
   "source": [
    "## Part 1: Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f73bed-2f4f-434b-bbaa-58d756a9ad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected splits in this directory. Loading splits ...\n",
      "Building output directory at ../data/out\n"
     ]
    }
   ],
   "source": [
    "# first, we have to check to see if all the splits are there ...\n",
    "assert np.all([f\"{i + 1}.csv\" in os.listdir(data_path) for i in range(n_splits)])\n",
    "print(\"Detected splits in this directory. Loading splits ...\")\n",
    "\n",
    "# then we read them in\n",
    "splits = [pd.read_csv(f\"{data_path}/{i + 1}.csv\") for i in range(n_splits)]\n",
    "\n",
    "# we convert every row of our CSV to a \"CSVMove object\" using df_to_CSVMove - we do so for all the splits\n",
    "# CSVMove is a class that is defined in the parsers.py file \n",
    "fold_data = [[csvmove for csvmove in df_to_CSVMove(split, warn = False)] for split in splits]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39935041",
   "metadata": {},
   "source": [
    "## Part 2: Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477a57ef",
   "metadata": {},
   "source": [
    "To ensure that the code is perfectly reproducible, we use a **single thread** and we set the manual seed to a number of our choosing. If we use multiple threads, the code will still work but the operating system may choose the order of the threads arbitrarily, leading to variation in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16a2d5d",
   "metadata": {},
   "source": [
    "You should see an output that looks something like: \n",
    "\n",
    "    Setting manual seed 10 for single-thread\n",
    "    Thread 0: Base Seed 10, Seed: 10, Random Number: 601088376405717203\n",
    "\n",
    "Note that if you run this code multiple times, the Random Number should be the same. This means our thread will be initialized with a particular random seed - as it runs, it will not be reinitialized, so the randomness will still proceed, but in a predictable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "14b8cef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting manual seed 10 for single-thread\n",
      "Thread 0: Base Seed 10, Seed: 10, Random Number: 601088376405717203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, Value, set_start_method\n",
    "random.seed(10)\n",
    "initialize_thread_pool(1, manual_seed = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df73ec0",
   "metadata": {},
   "source": [
    "We are now ready to begin running our model. We will begin with the default model and then feed it to our  `ModelFitter` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9ea19a9-5155-4b01-b72d-3923b413d76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validating split 1 against the other 4 splits\n",
      "[Preprocessing] Initial log-likelihood estimation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:12,  1.43s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m DefaultModel()\n\u001b[1;32m      2\u001b[0m model_fitter \u001b[38;5;241m=\u001b[39m ModelFitter(model, \n\u001b[1;32m      3\u001b[0m                            random_sample \u001b[38;5;241m=\u001b[39m random_sample, \n\u001b[1;32m      4\u001b[0m                            verbose \u001b[38;5;241m=\u001b[39m verbose, \n\u001b[1;32m      5\u001b[0m                            threads \u001b[38;5;241m=\u001b[39m threads)\n\u001b[0;32m----> 7\u001b[0m params, loglik_train, loglik_test \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_fitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfold_number\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# with (output_path / (\"params\" + str(i + 1) + \".csv\")).open('w') as f:\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     f.write(','.join(str(x) for x in params))\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# with (output_path / (\"lltrain\" + str(i + 1) + \".csv\")).open('w') as f:\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     f.write(','.join(str(x) for x in loglik_train))\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# with (output_path / (\"lltest\" + str(i + 1) + \".csv\")).open('w') as f:\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#     f.write(' '.join(str(x) for x in loglik_test) + '\\n')\u001b[39;00m\n",
      "File \u001b[0;32m~/Github/ninarow/model_fitting/model_fit.py:486\u001b[0m, in \u001b[0;36mModelFitter.cross_validate\u001b[0;34m(self, folds, i)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[1;32m    484\u001b[0m             train\u001b[38;5;241m.\u001b[39mextend(folds[j])\n\u001b[0;32m--> 486\u001b[0m params, loglik_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m test_tasks \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m move \u001b[38;5;129;01min\u001b[39;00m test:\n",
      "File \u001b[0;32m~/Github/ninarow/model_fitting/model_fit.py:406\u001b[0m, in \u001b[0;36mModelFitter.fit_model\u001b[0;34m(self, moves, bads_options)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03mGiven a set of moves, find the set of heuristic/search parameters that best fit the observations.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;124;03m@return The set of parameters that best correspond to the given moves, as well as their corresponding L-values.\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Preprocessing] Initial log-likelihood estimation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 406\u001b[0m average_l_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_initial_l_value_guess\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmoves\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m counts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_attempt_counts(\n\u001b[1;32m    409\u001b[0m     np\u001b[38;5;241m.\u001b[39marray(average_l_values), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mc)\n\u001b[1;32m    410\u001b[0m move_tasks \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Github/ninarow/model_fitting/model_fit.py:233\u001b[0m, in \u001b[0;36mDefaultModel.estimate_initial_l_value_guess\u001b[0;34m(self, fitter, moves)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mestimate_initial_l_value_guess\u001b[39m(\u001b[38;5;28mself\u001b[39m, fitter, moves):\n\u001b[1;32m    223\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;124;03m    Given a model fitter and a list of moves, estimate initial L-value guesses for each move.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m        A list of L-values corresponding to each of the given moves.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_l_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmoves\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Github/ninarow/model_fitting/model_fit.py:380\u001b[0m, in \u001b[0;36mModelFitter.estimate_l_values\u001b[0;34m(self, moves, params, sample_count)\u001b[0m\n\u001b[1;32m    378\u001b[0m l_values \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(sample_count)):\n\u001b[0;32m--> 380\u001b[0m     l_values\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loglik\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmove_tasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    382\u001b[0m average_l_values \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m move \u001b[38;5;129;01min\u001b[39;00m tqdm(moves):\n",
      "File \u001b[0;32m~/Github/ninarow/model_fitting/model_fit.py:335\u001b[0m, in \u001b[0;36mModelFitter.compute_loglik\u001b[0;34m(self, move_tasks, params)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m pool\n\u001b[1;32m    333\u001b[0m results \u001b[38;5;241m=\u001b[39m [pool\u001b[38;5;241m.\u001b[39mapply_async(\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimate_log_lik_ibs, (params, cutoff, shared_tasks,)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_workers)]\n\u001b[0;32m--> 335\u001b[0m [\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m    337\u001b[0m L_values \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m move \u001b[38;5;129;01min\u001b[39;00m shared_tasks:\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py:659\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    657\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 659\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/usr/local/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = DefaultModel()\n",
    "model_fitter = ModelFitter(model, \n",
    "                           random_sample = random_sample, \n",
    "                           verbose = verbose, \n",
    "                           threads = threads)\n",
    "\n",
    "params, loglik_train, loglik_test = model_fitter.cross_validate(fold_data, fold_number - 1)\n",
    "# with (output_path / (\"params\" + str(i + 1) + \".csv\")).open('w') as f:\n",
    "#     f.write(','.join(str(x) for x in params))\n",
    "# with (output_path / (\"lltrain\" + str(i + 1) + \".csv\")).open('w') as f:\n",
    "#     f.write(','.join(str(x) for x in loglik_train))\n",
    "# with (output_path / (\"lltest\" + str(i + 1) + \".csv\")).open('w') as f:\n",
    "#     f.write(' '.join(str(x) for x in loglik_test) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a6f368",
   "metadata": {},
   "source": [
    "We can examine the fitted model parameters below ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "75555658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted Model Parameters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stopping threshold</th>\n",
       "      <th>Pruning threshold</th>\n",
       "      <th>Gamma</th>\n",
       "      <th>Lapse rate</th>\n",
       "      <th>Opponent scale</th>\n",
       "      <th>Exploration constant</th>\n",
       "      <th>Center weight</th>\n",
       "      <th>FP C_act</th>\n",
       "      <th>FP C_pass</th>\n",
       "      <th>FP delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.143486</td>\n",
       "      <td>0.011378</td>\n",
       "      <td>0.237918</td>\n",
       "      <td>0.053329</td>\n",
       "      <td>1.304252</td>\n",
       "      <td>1.829346</td>\n",
       "      <td>0.435217</td>\n",
       "      <td>-0.667626</td>\n",
       "      <td>4.117251</td>\n",
       "      <td>5.289307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Stopping threshold  Pruning threshold     Gamma  Lapse rate  \\\n",
       "0            1.143486           0.011378  0.237918    0.053329   \n",
       "\n",
       "   Opponent scale  Exploration constant  Center weight  FP C_act  FP C_pass  \\\n",
       "0        1.304252              1.829346       0.435217 -0.667626   4.117251   \n",
       "\n",
       "   FP delta  \n",
       "0  5.289307  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Fitted Model Parameters\")\n",
    "param_df = pd.DataFrame(dict(zip(model_fitter.model.param_names, params), index = [0])).drop(\"index\", axis = 1)\n",
    "param_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c963c43",
   "metadata": {},
   "source": [
    "## Part 3: Saving Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbac9d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.699305559043987,\n",
       " 1.1783333333333332,\n",
       " 0.3,\n",
       " 0.7833333333333333,\n",
       " 3.378979594446965,\n",
       " 3.662621018934961,\n",
       " 0.6,\n",
       " 1.0262301587301585]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loglik_train.to_csv(f\"{output_path}/{fold_number}_lltrain.csv\", index = False)\n",
    "loglik_test.to_csv(f\"{output_path}/{fold_number}_lltest.csv\", index = False)\n",
    "param_df.to_csv(f\"{output_path}/{fold_number}_params.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
